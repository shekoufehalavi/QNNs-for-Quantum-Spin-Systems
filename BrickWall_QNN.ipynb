{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekvUUlqNG5uD"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from numba import jit, prange\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cProfile\n",
        "import pstats\n",
        "\n",
        "# --- Data Generation ---\n",
        "\n",
        "# Parameters\n",
        "num_qubits = 6\n",
        "matrix_size = 2**num_qubits\n",
        "num_repetitions = 1000\n",
        "Mz_values = np.zeros((num_repetitions, matrix_size))\n",
        "\n",
        "\n",
        "@jit(nopython=True, parallel=True)\n",
        "eigenvalues = []\n",
        "eigenvectors = []\n",
        "\n",
        "for repetition in range(num_repetitions):\n",
        "\n",
        "\n",
        "    #create random numbers for H.\n",
        "    np.random.seed(repetition)\n",
        "    J = np.random.uniform(low=-1, high=0, size=(num_qubits, num_qubits))\n",
        "    for i in range(num_qubits):\n",
        "        for j in range(num_qubits):\n",
        "            if i >= j:\n",
        "                J[i, j] = 0\n",
        "    J = (J + J.T)\n",
        "\n",
        "    np.random.seed(repetition +10)\n",
        "    K = np.random.uniform(low=-1, high=1, size=(num_qubits, num_qubits))\n",
        "    for i in range(num_qubits):\n",
        "        for j in range(num_qubits):\n",
        "            if i >= j:\n",
        "                K[i, j] = 0\n",
        "    K = (K + K.T)\n",
        "\n",
        "    np.random.seed(repetition +20)\n",
        "    h = np.random.uniform(low=-0.04, high=0.04)\n",
        "\n",
        "    np.random.seed(repetition +30)\n",
        "    g = np.random.uniform(low=-6, high=6, size=num_qubits)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # create the matrix of H.\n",
        "    matrix = np.zeros((matrix_size, matrix_size))\n",
        "    for i in range(matrix_size):\n",
        "        for j in range(matrix_size):\n",
        "            H_value = 0\n",
        "            for i1 in range(num_qubits):\n",
        "                for j1 in range(num_qubits):\n",
        "                    if j == i ^ (2 ** i1 + 2 ** j1):\n",
        "#This part adds contributions to H_value based on the coupling constants K and the XOR operation (^).\n",
        "#It checks if the bit-flipped indices i ^ (2 ** i1 + 2 ** j1) are equal to j and adds the corresponding K valeu.\n",
        "                        H_value += K[i1, j1]\n",
        "                    if j == i:\n",
        "                        sign = 1\n",
        "                        if (i & 2 ** i1) != 0:# & returns 1 if both the bits are 1, otherwise 0.\n",
        "                            sign = -sign\n",
        "                        if (i & 2 ** j1) != 0:\n",
        "                            sign = -sign\n",
        "\n",
        "                        H_value += sign * J[i1, j1]\n",
        "\n",
        "            for i1 in range(num_qubits):\n",
        "                if j == i ^ (2 ** i1):# external fields g for bit-flipped indices.\n",
        "                    H_value += g[i1]\n",
        "\n",
        "            if j == i:\n",
        "                H_value += h # external field h when j is equal to i.\n",
        "            matrix[i, j] = H_value\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # calculate eigenvalues and eigenvectors.\n",
        "    eigenval, eigenvect = np.linalg.eigh(matrix)\n",
        "   # print(eigenval)\n",
        "   # print(eigenvect)\n",
        "    min_eigenval = np.min(eigenval)\n",
        "    min_eigenvec = eigenvect[np.argmin(eigenval), :]\n",
        "\n",
        "    eigenvalues.append(min_eigenval)\n",
        "    eigenvectors.append(min_eigenvec)\n",
        "\n",
        "    #save the eigenvectors as a CSV file\n",
        "eigenvectors_csv = np.array(eigenvectors)\n",
        "np.savetxt('eigenvectors.csv', eigenvectors_csv, delimiter=',')\n",
        "    #print\n",
        "for repetition in range(num_repetitions):\n",
        "    print(\"Repetition\", repetition+1)\n",
        "    print(\"Eigenvalue:\", eigenvalues[repetition])\n",
        "    print(\"Eigenvector:\", eigenvectors[repetition])\n",
        "\n",
        "    print()\n",
        "\n",
        "  #creating the matrix of data, eigenvectors. each column is eigenvector of a certain H.\n",
        "eigenvectors_matrix = np.column_stack(eigenvectors)\n",
        "\n",
        "print(\"Eigenvectors Matrix:\")\n",
        "print(eigenvectors_matrix)\n",
        "\n",
        "\n",
        "Mzt = []\n",
        "for column in eigenvectors_matrix.T:\n",
        "    i = 0\n",
        "    Mz = 0\n",
        "    for component in column:\n",
        "        for n_prime in range(num_qubits):\n",
        "            if (2 ** n_prime) & i != 0 :\n",
        "                Mz += abs(component) ** 2  / num_qubits\n",
        "          #Mz += abs(component) ** 2 * (2 * ((2 ** n_prime) & i) - 1) / num_qubits\n",
        "        i += 1\n",
        "    Mz=2*Mz-1\n",
        "    Mzt.append(Mz)\n",
        "\n",
        "Mzt_row = np.array(Mzt)\n",
        "print(\"Mzt:\", Mzt,\"\\n\")\n",
        "print(len(Mzt),\"\\n\")\n",
        "print(Mz)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# prepare data, i choose minmax as the book chose\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(eigenvectors_matrix)\n",
        "\n",
        "# feature scaling, it calculate the number of columns and features\n",
        "num_features = scaled_data.shape[1]\n",
        "\n",
        "# Assuming you want to use the minimum number of samples between the two datasets\n",
        "min_samples = min(len(scaled_data), len(Mzt))\n",
        "\n",
        "# Adjust the size of both datasets\n",
        "scaled_data = scaled_data[:min_samples]\n",
        "Mzt = Mzt[:min_samples]\n",
        "\n",
        "# train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_data, Mzt, test_size=0.2, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) #0.25*0.8=0.2\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Validation set size:\", X_val.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n",
        "\n",
        "#-----------------------------------\n",
        "#part two: training\n",
        "#-----------------------------------\n",
        "\n",
        "import copy\n",
        "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit.quantum_info import Statevector\n",
        "from qiskit_aer import AerSimulator\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "class AdamOptimizer:\n",
        "    def __init__(self, model, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "        self.model = model\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.epsilon = epsilon\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "        self.t = 0\n",
        "\n",
        "    def compute_gradient(self, features, ansatz, num_qubits, labels):\n",
        "        if self.m is None:\n",
        "            self.m = np.zeros(len(ansatz.parameters))\n",
        "            self.v = np.zeros(len(ansatz.parameters))\n",
        "\n",
        "        gradient = np.zeros(len(ansatz.parameters))\n",
        "\n",
        "        # Calculate gradients using finite differences\n",
        "        weight_params = ansatz.parameters\n",
        "        original_params = {param: np.random.uniform(0, 2*np.pi) for param in weight_params}\n",
        "        for param_index, param in enumerate(weight_params):\n",
        "            for i in [1, -1]:\n",
        "                modified_params = original_params.copy()\n",
        "                modified_params[param] += i * self.epsilon\n",
        "                output_plus = self.model.forward(features, ansatz, num_qubits, modified_params)\n",
        "                loss_plus = self.model.mse_loss(output_plus, labels)\n",
        "                gradient[param_index] += i * (loss_plus - self.model.mse_loss(self.model.forward(features, ansatz, num_qubits, original_params), labels)) / (2 * self.epsilon)\n",
        "\n",
        "        # Update biased first and second moments\n",
        "        self.t += 1\n",
        "        self.m = self.beta1 * self.m + (1 - self.beta1) * gradient\n",
        "        self.v = self.beta2 * self.v + (1 - self.beta2) * (gradient ** 2)\n",
        "\n",
        "        # Bias correction\n",
        "        m_hat = self.m / (1 - self.beta1 ** self.t)\n",
        "        v_hat = self.v / (1 - self.beta2 ** self.t)\n",
        "\n",
        "        # Update parameters\n",
        "        delta_params = -self.learning_rate * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
        "\n",
        "        for param_index, param in enumerate(weight_params):\n",
        "            original_params[param] += delta_params[param_index]\n",
        "\n",
        "        return original_params\n",
        "\n",
        "class QuantumBrickWallModel:\n",
        "    def __init__(self, num_qubits, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "        self.num_qubits = num_qubits\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.epsilon = epsilon\n",
        "        self.circuit, self.parameters = self.build_qnn(num_qubits)\n",
        "        self.optimizer = AdamOptimizer(self, learning_rate, beta1, beta2, epsilon)\n",
        "        self.param_values = {param: np.random.uniform(0, 2*np.pi) for param in self.parameters}\n",
        "\n",
        "    def build_qnn(self, num_qubits):\n",
        "        qreg_q = QuantumRegister(num_qubits, 'q')\n",
        "        ansatz = QuantumCircuit(qreg_q)\n",
        "        ansatz.h(range(num_qubits))\n",
        "\n",
        "        cnot_pairs = [(i, i+1) for i in range(0, num_qubits-1, 2)]\n",
        "        cnot_pairs += [(i, i+1) for i in range(1, num_qubits-1, 2)]\n",
        "\n",
        "        parameters = []\n",
        "        layer = 3\n",
        "        for i in range(layer):\n",
        "            for j, (control, target) in enumerate(cnot_pairs):\n",
        "                theta = Parameter(f'theta_{i}_{j}')\n",
        "                phi = Parameter(f'phi_{i}_{j}')\n",
        "                lam = Parameter(f'lam_{i}_{j}')\n",
        "                gamma = Parameter(f'gamma_{i}_{j}')\n",
        "                parameters += [theta, phi, lam, gamma]\n",
        "\n",
        "                ansatz.cu(theta, phi, lam, gamma, qreg_q[control], qreg_q[target])\n",
        "\n",
        "        return ansatz, parameters\n",
        "\n",
        "    def forward(self, features, ansatz, num_qubits, param_bindings):\n",
        "        output_list = []\n",
        "\n",
        "        for state_vector in features:\n",
        "            qc = QuantumCircuit(num_qubits)\n",
        "            qc.initialize(state_vector, range(num_qubits))\n",
        "            qc.compose(ansatz, inplace=True)\n",
        "            cr = ClassicalRegister(1, name=\"c\")\n",
        "            qc.add_register(cr)\n",
        "            qc.measure(num_qubits - 1, cr[0])\n",
        "\n",
        "            bound_qc = qc.assign_parameters(param_bindings)\n",
        "\n",
        "            backend = AerSimulator()\n",
        "            job = backend.run(bound_qc, shots=1000)\n",
        "            result = job.result()\n",
        "            counts = result.get_counts(bound_qc)\n",
        "\n",
        "            if '0' in counts and '1' in counts:\n",
        "                exp_val = (counts['0'] - counts['1']) / sum(counts.values())\n",
        "            elif '0' in counts:\n",
        "                exp_val = counts['0'] / sum(counts.values())\n",
        "            else:\n",
        "                exp_val = -counts['1'] / sum(counts.values())\n",
        "\n",
        "            output_list.append(exp_val)\n",
        "\n",
        "        return output_list\n",
        "\n",
        "    def mse_loss(self, output, labels):\n",
        "        return np.mean(np.square(np.array(labels) - np.array(output)))\n",
        "\n",
        "\n",
        "    def evaluate(self, features, labels):\n",
        "        output = self.forward(features, self.circuit, self.num_qubits, self.param_values)\n",
        "        loss = self.mse_loss(output, labels)\n",
        "        return loss\n",
        "\n",
        "    def predict(self, features):\n",
        "        predictions = self.forward(features, self.circuit, self.num_qubits, self.param_values)\n",
        "        return predictions\n",
        "\n",
        "    def train(self, train_features, train_labels, val_features, val_labels, num_epochs):\n",
        "        loss_history = []  # Initialize loss history\n",
        "        val_loss_history = []  # Initialize validation loss history\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Training step\n",
        "            output = self.forward(train_features, self.circuit, self.num_qubits, self.param_values)\n",
        "            train_loss = self.mse_loss(output, train_labels)\n",
        "            self.param_values = self.optimizer.compute_gradient(train_features, self.circuit, self.num_qubits, train_labels)\n",
        "\n",
        "            # Validation step\n",
        "            val_loss = self.evaluate(val_features, val_labels)\n",
        "\n",
        "            # Append losses to history\n",
        "            loss_history.append(train_loss)\n",
        "            val_loss_history.append(val_loss)\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
        "\n",
        "        # Plot the training and validation loss\n",
        "        plt.plot(loss_history, label='Train Loss')\n",
        "        plt.plot(val_loss_history, label='Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training and Validation Loss Evolution')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        # Return final validation loss for further evaluation\n",
        "        return val_loss\n",
        "\n",
        "    def test(self, test_features, test_labels):\n",
        "        test_loss = self.evaluate(test_features, test_labels)\n",
        "        print(f\"Test Loss: {test_loss}\")\n",
        "        return\n",
        "\n",
        "\n",
        "# ---------Run the code--------\n",
        "\n",
        "# Create the model\n",
        "model = QuantumBrickWallModel(num_qubits=num_qubits)\n",
        "\n",
        "# Predictions on test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "val_loss = model.train(X_train, y_train, X_val, y_val, num_epochs=150)\n",
        "\n",
        "\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Training completed in {elapsed_time:.2f} seconds\")\n",
        "\n",
        "# Test the model\n",
        "test_loss = model.test(X_test, y_test)\n",
        "\n"
      ]
    }
  ]
}